{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 tactics for handling imbalanced classes in machine learning:\n",
    "\n",
    "## 1. Up-sample the minority class\n",
    "## 2. Down-sample the majority class\n",
    "## 3. Change your performance metric\n",
    "## 4. Penalize algorithms (cost-sensitive training)\n",
    "## 5. Use tree-based algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>balance</th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  balance  var1  var2  var3  var4\n",
       "0       B     1     1     1     1\n",
       "1       R     1     1     1     2\n",
       "2       R     1     1     1     3\n",
       "3       R     1     1     1     4\n",
       "4       R     1     1     1     5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dataset\n",
    "df = pd.read_csv('balance-scale.data', names=['balance', 'var1', 'var2', 'var3', 'var4'])\n",
    "\n",
    "# Display example observations\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R    288\n",
       "L    288\n",
       "B     49\n",
       "Name: balance, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count of each class\n",
    "df['balance'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    576\n",
       "1     49\n",
       "Name: balance, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform into binary classification (scale is either balanced or not)\n",
    "df['balance'] = [1 if b=='B' else 0 for b in df.balance]\n",
    "df['balance'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9216\n"
     ]
    }
   ],
   "source": [
    "### Only .08 were balanced so if we always guessed unbalanced (predicted 0), we would have .92 accuracy\n",
    "\n",
    "# Example of dangers of imbalanced classes: Logistical regression with default parameters\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Separate into target and input variables\n",
    "y = df.balance\n",
    "X = df.drop('balance', axis = 1)\n",
    "\n",
    "# Train model\n",
    "clf0 = LogisticRegression().fit(X, y)\n",
    "\n",
    "# Predict on training set\n",
    "pred_y0 = clf0.predict(X)\n",
    "\n",
    "# Check the accuracy\n",
    "print(accuracy_score(pred_y0, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# Great accuracy! But wait... is the model predicting anything besides 0?\n",
    "print(np.unique(pred_y0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# :( :( :( \n",
    "# We need a better way of doing things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Up-sample Minority Class\n",
    "### Randomly duplicate observations from minority class to reinforce its signal\n",
    "#### 1. First, we'll separate observations from each class into different DataFrames.\n",
    "#### 2. Next, we'll resample the minority class with replacement, setting the number of samples to match that of the majority class.\n",
    "#### 3. Finally, we'll combine the up-sampled minority class DataFrame with the original majority class DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    576\n",
       "0    576\n",
       "Name: balance, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# module for resampling\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate minority and majority classes\n",
    "df_minority = df[df.balance==1]\n",
    "df_majority = df[df.balance==0]\n",
    "\n",
    "# Upsample minorty class\n",
    "df_minority_upsampled = resample(df_minority,\n",
    "                                replace = True, # Sample with replacement\n",
    "                                n_samples = 576, # match majority class\n",
    "                                random_state = 123) # reproducable results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "# Display new class counts\n",
    "df_upsampled.balance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "0.5138888888888888\n"
     ]
    }
   ],
   "source": [
    "# Train model on upsampled dataset\n",
    "\n",
    "y = df_upsampled.balance\n",
    "X = df_upsampled.drop('balance', axis = 1)\n",
    "\n",
    "clf1 = LogisticRegression().fit(X, y) # train\n",
    "\n",
    "pred_y1 = clf1.predict(X) # predict\n",
    "\n",
    "# Is our model still predicting only 0s?\n",
    "print(np.unique(pred_y1))\n",
    "\n",
    "# What is the accuracy?\n",
    "print(accuracy_score(y, pred_y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low accuracy, but predicting more than 1 class is a step in the right direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Down-Sample Majority Class\n",
    "\n",
    "### The most common heuristic for doing so is resampling without replacement.\n",
    "### The process is similar to that of up-sampling. Here are the steps:\n",
    "\n",
    "#### 1. First, we'll separate observations from each class into different DataFrames.\n",
    "#### 2. Next, we'll resample the majority class without replacement, setting the number of samples to match that of the minority class.\n",
    "#### 3. Finally, we'll combine the down-sampled majority class DataFrame with the original minority class DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    49\n",
       "0    49\n",
       "Name: balance, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate majority and minority classes\n",
    "df_majority = df[df.balance==0]\n",
    "df_minority = df[df.balance==1]\n",
    " \n",
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=49,     # to match minority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine minority class with downsampled majority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    " \n",
    "# Display new class counts\n",
    "df_downsampled.balance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "0.5816326530612245\n"
     ]
    }
   ],
   "source": [
    "# Train model based on logistical regression\n",
    "\n",
    "# Separate input features (X) and target variable (y)\n",
    "y = df_downsampled.balance\n",
    "X = df_downsampled.drop('balance', axis=1)\n",
    " \n",
    "# Train model\n",
    "clf_2 = LogisticRegression().fit(X, y)\n",
    " \n",
    "# Predict on training set\n",
    "pred_y_2 = clf_2.predict(X)\n",
    " \n",
    "# Is our model still predicting just one class?\n",
    "print( np.unique( pred_y_2 ) )\n",
    " \n",
    "# How's our accuracy?\n",
    "print( accuracy_score(y, pred_y_2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not just predicting one class, results seem slightly better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Change Your Performance Metric\n",
    "\n",
    "#### For a general-purpose metric for classification, we recommend Area Under ROC Curve (AUROC). Intuitively, AUROC represents the likelihood of your model distinguishing observations from two classes. In other words, if you randomly select one observation from each class, what's the probability that your model will be able to \"rank\" them correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4541919722647962,\n",
       " 0.4820596221328388,\n",
       " 0.46862327066392495,\n",
       " 0.4786837883268913,\n",
       " 0.5814385682015971]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To calculate AUROC, you'll need predicted class probabilities instead of just the predicted classes. \n",
    "# You can get them using the .predict_proba() function like so:\n",
    "\n",
    "# Predict class probabilities using downsampled data\n",
    "prob_y_2 = clf_2.predict_proba(X)\n",
    " \n",
    "# Keep only the positive class\n",
    "prob_y_2 = [p[1] for p in prob_y_2]\n",
    "\n",
    "prob_y_2[:5] # Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5680966264056644\n"
     ]
    }
   ],
   "source": [
    "# How did this model (trained on the down-sampled dataset) do in terms of AUROC?\n",
    "print(roc_auc_score(y, prob_y_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47480216576426487\n"
     ]
    }
   ],
   "source": [
    "# How does this compare to the original model trained on the imbalanced dataset?\n",
    "\n",
    "prob_y0 = clf0.predict_proba(X)\n",
    "prob_y0 = [p[1] for p in prob_y0]\n",
    " \n",
    "print( roc_auc_score(y, prob_y0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: last value should be 0.530718537415. \n",
    "# if you got an AUROC of 0.47, it just means you need to invert the predictions because Scikit-Learn is \n",
    "# misinterpreting the positive class. AUROC should be >= 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Penalize Algorithms (Cost-Sensitive Training)\n",
    "\n",
    "### The next tactic is to use penalized learning algorithms that increase the cost of classification mistakes on the minority class. A popular algorithm for this technique is Penalized-SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# During training, we can use the argument class_weight='balanced' \n",
    "# to penalize mistakes on the minority class by an amount proportional to how under-represented it is.\n",
    "\n",
    "# We also want to include the argument probability=True if we want to enable probability estimates for SVM algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "0.688\n"
     ]
    }
   ],
   "source": [
    "# Separate input features (X) and target variable (y)\n",
    "y = df.balance\n",
    "X = df.drop('balance', axis=1)\n",
    "\n",
    "# Train Model\n",
    "clf_3 = SVC(kernel = 'linear', \n",
    "           class_weight = 'balanced', # Penalize\n",
    "           probability = True)\n",
    "\n",
    "clf_3.fit(X, y)\n",
    "\n",
    "# Predict on training set\n",
    "pred_y_3 = clf_3.predict(X)\n",
    "\n",
    "# Is our model predicting more than 1 class?\n",
    "print(np.unique(pred_y_3))\n",
    "\n",
    "# What is our accuracy?\n",
    "print(accuracy_score(y, pred_y_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5305236678004536\n"
     ]
    }
   ],
   "source": [
    "# What about AUROC?\n",
    "prob_y_3 = clf_3.predict_proba(X)\n",
    "prob_y_3 = [p[0] for p in prob_y_3] # changed 1 to 0 because misinterpreting class\n",
    "print( roc_auc_score(y, prob_y_3) )\n",
    "# 0.5305236678"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Use Tree-Based Algorithms\n",
    "\n",
    "#### Decision trees often perform well on imbalanced datasets because their hierarchical structure allows them to learn signals from both classes. In modern applied machine learning, tree ensembles (Random Forests, Gradient Boosted Trees, etc.) almost always outperform singular decision trees, so we'll jump right into those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "0.9744\n"
     ]
    }
   ],
   "source": [
    "# Train random forest on imbalanced dataset\n",
    "\n",
    "y = df.balance\n",
    "X = df.drop('balance', axis = 1)\n",
    "\n",
    "# Train model\n",
    "clf_4 = RandomForestClassifier()\n",
    "clf_4.fit(X, y)\n",
    "\n",
    "# Predict\n",
    "pred_y_4 = clf_4.predict(X)\n",
    "\n",
    "# Is our model still predicting 1 class?\n",
    "print(np.unique(pred_y_4))\n",
    "\n",
    "# What is our accuracy?\n",
    "print(accuracy_score(y, pred_y_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9954294217687076\n"
     ]
    }
   ],
   "source": [
    "# Wow!\n",
    "\n",
    "# AUROC Score\n",
    "# What about AUROC?\n",
    "prob_y_4 = clf_4.predict_proba(X)\n",
    "prob_y_4 = [p[1] for p in prob_y_4]\n",
    "print( roc_auc_score(y, prob_y_4) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O_O\n",
    "\n",
    "# Note: While these results are encouraging, the model could be overfit, \n",
    "# so you should still evaluate your model on an unseen test set before making the final decision."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
